 For example, the implementation may be slightly different than described in the pseudocode and thus the correctness proof doesn't directly transfer to it. Or maybe the analysis assumes the wrong complexity for some basic operations -- in other words, the model of computation doesn't fit the programming language and/or hardware.
 


In type theory, as the name suggests, the basic objects of interest are types. In order to be meaningful, a type must first be formed using a formation rule. For example, the formation rule for $\N$ says that we can always form the type $\N$ of natural numbers. However, this needs not be the case for all types -- sometimes to form a type we must make an assumption or even several assumptions.

We keep track of assumptions using contexts. There are two ways of forming contexts. First, there's the empty context. Second, if $\Gamma$ is a context and we can form the type $A$ in $\Gamma$, written $\Gamma \vdash A$, then $\Gamma, x : A$ is also a context -- it is the context $\Gamma$ extended with we can extend the context $\Gamma$ with an assumption of the form $x : A$, given that the name $x$ does not already appear in $\Gamma$.

For example, if in a context $\Gamma$ we can form the types $A$ and $B$, written $\Gamma \vdash A$ and $\Gamma \vdash B$, then we can form the type of functions from $A$ to $B$, written $\Gamma \vdash A \to B$.

The next thing we are interested in is evaluation of terms. For example, we would expect that $2 + 2 : \N$ evaluates to $4 : \N$ and this is indeed the case. However, in almost all presentations of type theory instead of evaluation we talk about convertibility -- the least equivalence relation induced by evaluation (that is, we can think of two terms as being convertible if they evaluate to the same result). To formally state that $2 + 2$ and $4$ are convertible, we write $\Gamma \vdash 2 + 2 \equiv 4 : \N$. Rules that govern the behaviour of convertibility, similarly to rules for term manipulation, come in two genres: computation rules and uniqueness rules.

\begin{listing}[H]

\begin{minted}
[
    frame=lines,
    bgcolor=CoqIDE,
    linenos
]{Coq}
    
Class Semigroup (A : Type) : Type :=
{
    op : A -> A -> A;
    assoc : forall x y z : A, op (op x y) z = op x (op y z);
}.

\end{minted}

\caption{Semigroups represented with typeclasses}
\label{SgrClass}

\end{listing}

\chapter{A man, a plan, a canal -- MSc thesis}

\section{Design}
\begin{itemize}
    \item First step: specification (describe the path from intuition to formal spec).
    \item Second step: design (describe the path from the concrete to the abstract by tracing a stub proof of correctness).
    \item We shouldn't require proofs in order to run programs. Clou: packed vs unpacked classes/records/modules.
\end{itemize}

\section{Techniques}
\begin{itemize}
    \item General recursion: Bove-Capretta method as the way to go.
    \item Functional induction as the way-to-go proof technique. Mention the Equations plugin.
\end{itemize}

\section{Topics}
\begin{itemize}
    \item Quicksort: in functional languages we have so powerful abstractions that we can actually implement \*algorithms\* and not just programs.
    \item  Braun mergesort: in order not to waste resources, we sometimes have to reify abstract patterns, like the splitting in mergesort.
    \item Binary heaps: a case study to show the basic workflow and that it's not that obvious how to get basic stuff right.
    \item Cool data structures: ternary search trees, finger trees.
\end{itemize}